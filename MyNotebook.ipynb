{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "245F9a1rlL7m",
    "outputId": "8544daa5-5ada-4f3e-d118-71febc31f11d"
   },
   "outputs": [],
   "source": [
    "!pip -q install --upgrade \\\n",
    "  \"transformers>=4.44,<4.47\" \\\n",
    "  \"peft>=0.12.0\" \\\n",
    "  \"trl>=0.9.6\" \\\n",
    "  \"accelerate>=0.34.2\" \\\n",
    "  \"bitsandbytes>=0.44.0\" \\\n",
    "  \"datasets>=2.20.0\"\n",
    "\n",
    "import os, sys, time\n",
    "print(\" Deps installed. Restarting runtime to load them cleanly...\")\n",
    "time.sleep(1)\n",
    "os.kill(os.getpid(), 9)  # Colab auto-restart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvxWzdodoOi8",
    "outputId": "51168198-f328-4ad5-d323-545f1b88ac7f"
   },
   "outputs": [],
   "source": [
    "import torch, warnings\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\" Imports OK. torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401,
     "referenced_widgets": [
      "509185fb6abd4e35b934574d9d145223",
      "22a5c05212764e10ac3287b754f5297c",
      "2bac0dcaca24474fa985393df11ad78a",
      "6542ac2cb4c8491390eccc64c0002979",
      "04ad565fd0644559ab57103760615ae5",
      "13714d399c20450787aaac4b8facff2a",
      "ff59870b91de48579778b67bd67ef00c",
      "160ed1f241b24a05a8e69a1aeb3f89bf",
      "144c5d233d09465192b2ab4cf126e968",
      "ac1c0d622e8a4f12a0f857472f0f8bbc",
      "eec0e6ffe9794412ae5d477a531865ce",
      "4a42062d1a50401d91119a122eb7c656",
      "e9a65e3a260f4b179c27f406cd65439f",
      "8df12a91fe9c4d2f9a281cd8478f684f",
      "e89307a72be842978c1b09594d944494",
      "4a8ed4c6e88346f7bf20ba81df8df134",
      "14e6d25c73ed4e4abd66c63db3aa0943",
      "9f4ed370f9b84db8adc0b50903871f15",
      "fc485a668fab4d6985e8ec9dbb16c2c0",
      "4df818ab52cc45c69b04798c0cd0799d",
      "bc12a2a9b4094bcba73fa17a86a3cb18",
      "7c20820f60c74437a813a8cfdb731144",
      "c30b9f8ee6654dcf8709c6cc43efc2f7",
      "b4d554e6f7424eaeb6bb8ceb5cd57cce",
      "a704426afe5743f7925765a7c7a83009",
      "3daef1a53aec45b3bcb5a463a71272ea",
      "03ff63cdcbd84c00bb805ced0da97811",
      "74141ee1f09f483eaa4e11d45ab5eddd",
      "0a1eea55d7b14623bd4c9ff662c72aae",
      "6b890346d0764b069e4dabef82977d8c",
      "797093a88e4f4746842a9247b88e222e",
      "cdf778934d784da79e8c96944d09adf1",
      "7e2f2892b8644033890d51d294f5a7b5"
     ]
    },
    "id": "NabQi010qSVz",
    "outputId": "8307889a-7193-485d-a74d-0f9c47e8fce6"
   },
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": \"/content/train.csv\",\n",
    "        \"validation\": \"/content/val.csv\",\n",
    "        \"test\": \"/content/test.csv\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "print(\"Sample row:\", dataset[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 702,
     "referenced_widgets": [
      "c40cfa377dee476d9683834405845cdb",
      "f51569b2cd944652bc25b2ba9398b957",
      "06ed916fb7e74900bbb7b28b454e442e",
      "20bac5be98f64f4496c25674245e8a9c",
      "574bf29cb3044d7b908157c732c27de4",
      "71251a029f1d4b0c92c1af65919cf83d",
      "9807498febeb40588b2c55ca82cf0ae2",
      "ee6a38b328d8463592ea0c48c916f5c6",
      "f7f59037dce84ab3abedf6d53c4a09df",
      "f7db7c87e2f0498ab375ed3db61d34d4",
      "2359325e6f4b4d13a938306b41c8f6d4",
      "574d0d6a42c84cfcb9512d6d0fe88d0c",
      "a940807efb614daa812261ebee7207fc",
      "641e2aaef4e9466382da343cf86dd048",
      "46479858a1b1411eb68e2e0372c3d793",
      "6e93ef4453b449ce9beeb1a66da5b00d",
      "0ba4f16fdcf946428cbce160038b1846",
      "710256e004d14da1a23e40eaa9f8bc08",
      "b2afc1c3de45417e94e264189b11f809",
      "972ac44bf30d4355a2c1a2ae33d3b216",
      "fd4c6227f77345f2b5b5559334091ce4",
      "e15e0ed1ea3b4552b5e8b277a9ac890d",
      "df46e6caee104fb89b6d4b267a173170",
      "c25397367b8145dc9d2385bcb60fe3d9",
      "cd4e20ed92b54981918a9944cd8b0757",
      "0d91811bc06344a9a84db5833abab660",
      "3aec9bb5f5e540b39b82225e64cfff60",
      "bbb0f0af710341b3b6330c5a1167c010",
      "b18b85fa91e645359977f91b6eb75592",
      "812dd20ae03046d682d74241e25c3e4b",
      "a7df99740ae64104a00f3516ff9d0883",
      "cd68917798594bc597313990cc9711f6",
      "e6fd4901aa9848f69c5d405816d4d19c"
     ]
    },
    "id": "bkuEIDBYniEl",
    "outputId": "734d651d-5158-496d-b2b0-ecce5ab7ee8d"
   },
   "outputs": [],
   "source": [
    "# Build a single prompt string per row: Instruction + Input + Response\n",
    "INSTR_CANON = \"Explain the following log and propose a fix. Return exactly:\\nCause:\\n<2-3 lines>\\nFix:\\n<1 line>\"\n",
    "\n",
    "def format_row(ex):\n",
    "    instr = (ex.get(\"instruction\") or INSTR_CANON).strip()\n",
    "    inp   = (ex.get(\"input\") or \"\").strip()\n",
    "    out   = (ex.get(\"output\") or \"\").strip()\n",
    "    return {\n",
    "        \"text\": f\"### Instruction:\\n{instr}\\n\\n### Input:\\n{inp}\\n\\n### Response:\\n{out}\"\n",
    "    }\n",
    "\n",
    "cols = dataset[\"train\"].column_names\n",
    "dataset_fmt = dataset.map(format_row, remove_columns=cols)\n",
    "\n",
    "print(dataset_fmt)\n",
    "print(\"\\nPreview:\\n\", dataset_fmt[\"train\"][0][\"text\"][:400], \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899,
     "referenced_widgets": [
      "c60f945acefe4f4b91440e9c4e02359b",
      "fc6db817330742b1a78672e14db5e669",
      "51307746d0eb410b8a7e45fe2b622de4",
      "c6c34d28a67748a19f520398a9c87054",
      "efe3d60781434bbca111af206f0ca2e2",
      "23c2a8ab7dd5413ebe2a0bdd89606f78",
      "7df620b7ed0845c584e81f0b56778cd8",
      "53af6873b4ce4dd391a6865842c426ab",
      "95e451b5aab34e44a60e2b91f3c5524f",
      "0c8f7693be9747b3bb6677e64da7df69",
      "eb841575293f41f08b9f56879513d8c8",
      "20cc0827d93643bc95b34b4a781b4df8",
      "a1444b2bda5d4c2694438a0d2f13a2d4",
      "2989fe0d26304bbf9c79cbb3a4e0d05d",
      "77113b0016994b3c85d08da4304f550c",
      "2cb711e451c14129bd30e30edad6f9f9",
      "131d2d63d3d2471c99113ab0b2d36b3c",
      "78f9c9f933b645c393933235bb34ef83",
      "0aa2685470294f0e9e2459fa79260f3f",
      "5416b19ca9f1440fbb0c1acd8b8bfcf0",
      "b771a8580deb478da5fbbdca6e7ce01d",
      "9a27bf81c87f45d78f75b2c55d2163a8",
      "433f22d943914d71b485ffd379e4c6f8",
      "55c5090880e040a2bc612895ab2b32a0",
      "fc5e49c47071432881edadd841e79428",
      "998f45384fa4465bbd33e21f372c1a9e",
      "99774559372d406d89e8beb6c38779fd",
      "42be55a8da0647cf95452ed06338dac4",
      "102acc14d1a44e249481c39886b8c4f1",
      "b1153c33d01d4f7a9b8630ccbe395321",
      "f65e050cbeca4ff0b2b8ab9eb98a132d",
      "49bfb235e300439a98fcc04be2433295",
      "11e8e5001bee486db292da9d10ad595e",
      "6aee61e7faaf46d0b55d5edbf7f6c6a8",
      "a09961b3445443b593ddcc4f9dd9edce",
      "bfd118ea225a4f0aade8f624269e76e5",
      "060cada4619d4e02a78539083d5d9749",
      "37d43b52ba194fa4baf3a71c865a65c7",
      "7a67db5b02c847fe82ac12b732622321",
      "25aca5ee39cc473f9e135af6b6d7468a",
      "f7e0de5ddd74460eafc7de6f19ac3671",
      "3a74f36d46f943f4b02631f7a3be777c",
      "8ed20bc858714b73912b69f2a160a70b",
      "57cb2667b6974d52955f586a2a41aa8d",
      "b249669233e549f084b8ecb5f3fac05d",
      "f60fe65028f345d1b4d79979793f221d",
      "85c1e368db3541e59782ffe3bc3ae3df",
      "bee5767ee8c8457092e8023fba86598a",
      "46822bd4a2424a0d83771b5f42df84af",
      "4105c47deea740aaaf6cbf733d36541c",
      "9baa4f52e66a4e1f942354b9c89360ea",
      "fe6e31077f034bf59526eb7aace5f747",
      "3e0fddb7ee7d4ed19b11efbe2ece6682",
      "cfa9f5f95936452c822da149f83aad85",
      "57ef89e4cded49d288711b7fee320dfc",
      "0b2623c320dc42708c16ba73ff64905d",
      "b14b725e9b7b4fd2bb1c508f3e7745a3",
      "8827590557074c2097b0306a638b05b7",
      "62662a30c82e496cb03824ce32fc8858",
      "4a51581b109f4cbbbca6ae7950f82aee",
      "8d9c5f7c389e47e190729ecd8dd63f47",
      "2f78ac789eb94ccdb6bcd13c9a3b27b4",
      "61384f1e3286436196c91935b899a72a",
      "c0a3d6bca14d41ffb9ce625420625e56",
      "8bf97231980946e8bf1ca202fd046c19",
      "0228afd075e94d408269b279ac2f318c",
      "cf95a9391d4b4851afd92842b2aa3ad7",
      "ed7e7f3f77874c3fa974ce87548c8d11",
      "5550031ec34a455a845482127128730d",
      "09a7214150d8423bb597b496c6a28263",
      "42056365873646febabffdeed5a90569",
      "bf93d0e5931d4cf092de6805407e1546",
      "5d6b94ec9a9c4d2ab64160e54fb02d16",
      "e816ea28f1e147b88283511f1c59fb35",
      "414987d6ba8844c38dfab5682ab45ea6",
      "f2d2d0b2e6564c6d80623e1913c28d4b",
      "9a312405e0a04286bc27ddfe039284f9",
      "6c3ffe19778746fc880815e442804de9",
      "683d02f2d1a04bc28b88bca2abfff889",
      "b445bdc8da6542f1926bff4207ed5dd4",
      "3a878ef1c0014910a9acbf92d95b13b7",
      "00c9769d71d94b64a88c866c54f7a081",
      "a1277a37ab814a54b2f9a23908903c3e",
      "155f4e645edd48f18aee8eeb040139b7",
      "c6b1a877b1084c5f970c1d61774d8590",
      "d41386b3119142e5a89e64171b1f5197",
      "6b6ce0e6ff3b42dd9bd6595a117f3d2c",
      "d7cfa4a7a18c4d69b11c8391ce23bda9",
      "70fc143f2d7a4f9f9e38d39d9184df30",
      "202965176f664a0c83ffe491cb0416f7",
      "5f486f58d6f54d368dd4c872159b96b4",
      "68db9277db114f9b83e03cd92c0be3e5",
      "2dc63612648947d1a3b370904bf80108",
      "8f1deb6d269f40d9ad0e13b713a70d8d",
      "a030930f263345818ef56d9182c4fcb1",
      "d2068a06cdda4e89b618e6fd1e2fecfe",
      "a29fbeaafa0c45e890b22989284526c3",
      "0e14062d6e7b47b1904bd88deca9f062",
      "3ced8449181349f48c16c46777100e67",
      "83d72c841d684cd4b56ed1920d607b55",
      "4038fdfca6ab40aca401e789dab33010",
      "0d5f781e242f4126aa53212ea357c459",
      "e6a161eed4544b4590a28ce41733709c",
      "3108f71b815d43f8ba9916a0d3adc702",
      "345201e05e9c4e0eb55e921d03a0dc33",
      "a315c207c69745aa85dfb50143f7424a",
      "2a51fb0d31494691a74195b73f94b465",
      "71f8a0e0723d4f3e9497f601cf44a0bf",
      "5f3e3f3ff83e491281f23668880d4c6c",
      "1bc3d1ce47634855b7fafed6ef97516b",
      "33b9ed9f37394f23abd702957b5e28f4",
      "6c4fa6ff57e2481094df2a820254dfbb",
      "2492dff905cf4ec6ac6dd4a9d252430e",
      "32806fb8466f4feda721c571a62a1f55",
      "606c964fdc2e4b679f83b3ab39f4c3a6",
      "96f275b58f664e3cb5cb969e4d35aa76",
      "aa471905c55b4d78bd256b697fd967cf",
      "128979b871294332bfb7afbb203b39f0",
      "8742334615d148a98cb9d9bc5a055c3d",
      "173d7b692245421f91eb79f8d026b244",
      "8c6b47f4cdc84c6daa17c5edb7df8ca4",
      "0dc24dea264949d08be98150ab951d63",
      "105d309a88264c108baddc68b118e133",
      "388941d1731d4461b2fe81b0e2196d59",
      "de0d67dff06e4c9587d17de08ae4ef8d",
      "5d802e4c2b254ea1a5fb4f3e75435aea",
      "0333f5cccc084febb4b3357714f4bad1",
      "004a4c6b772140f69736b4645b3f7899",
      "2c5fec173be544baa54dedf9fd3acda1",
      "7ed371aece7043c481eed7b2bfcc168c",
      "8685c117222b4655a1f2fe91f3170d12",
      "f60d2d76a044468faffbf93372498441",
      "ddfd606a4c3542268c8ae817bb338c2f",
      "83c91116d3364bac81bda4e24ed2ec92",
      "2ec2beb8870643e688631803fd916bfa",
      "ba82f88b6f014543a744de8bb82a3a33",
      "9f0c4d66f24c445d91ba289757398f25",
      "cb725a44db48480d9e29a0184ff6f8b7",
      "3d75f715cf2943b087d666bc48440ade",
      "07092a4dfc21406187e560f771b3c35a",
      "b0f1151b4e0d42ebb9f15801a93964dc",
      "04bae81bc6be4ddaa15b637c3f8dbf7d",
      "1aba0655bfc04b998820932e0b45cf5c"
     ]
    },
    "id": "O7yXcvjMn9d6",
    "outputId": "058c0b42-5946-4203-b7e1-6cb2b3a184fd"
   },
   "outputs": [],
   "source": [
    "# Load a good, ungated base model in 4-bit for QLoRA\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "bnb_cfg = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_cfg,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Optional memory saver for Colab\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "print(\"✅ Model :\", model_id)\n",
    "print(\"Tokenizer :\", tok)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sA5CGmbAzUe",
    "outputId": "e4872bd4-cd48-4f81-ceac-c521e6e54ee0"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "\n",
    "# 1) Make k-bit training-safe\n",
    "model.config.use_cache = False\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(\n",
    "    model, use_gradient_checkpointing=True\n",
    ")\n",
    "\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=16, lora_alpha=32, lora_dropout=0.05, bias=\"none\",\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"up_proj\",\"down_proj\",\"gate_proj\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.train()\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352,
     "referenced_widgets": [
      "d897466c0d1f41c2ab5f8b9d5584089e",
      "d2c2cd91997446af9fc2007b14c98230",
      "35ff43ea755549fd874bdb72cfd978a7",
      "e20e45c25aa64cb8ae0b986b6426f93c",
      "550e12da6ef34025a9a74a34f175b1de",
      "4115e948e9cc4d1a8ab77383403ee586",
      "c131d4fff4f84ce2afc22de148a8cec9",
      "2b38d16c60d24b85bf1e356d3be8e2ce",
      "f926fab0eb8447b897479fa15a8caa04",
      "5467d4f91c9f4b34bdf5783146bed631",
      "c78792376653441d9138951ef0fe8e96",
      "11124da3dfc84a30beb50eaaaee94f7d",
      "a4078a6d6ff340269efa2012af4b646a",
      "2b00d9c7b2ee43c4832f8b2ec0eb71f9",
      "e9251b3066a6439a83694ef5f69a1373",
      "78afa44f7fec4ad48729a7d9aed433bd",
      "d5e4c42f8a5f4fccad816260b3508693",
      "fd4dda046a9d4eb2bff5b2c7aa9bbe76",
      "10d0cf136cd3407aad824873c0a93841",
      "4c562a66b7ed41a19d9b697c6ac04b7f",
      "c6eb80102e634235a7cee0d2de9f6281",
      "51b3d921eb7e49dfaf7356dcd637ff4b",
      "9eeab441e70a4f6da5cf9f5061aa221e",
      "83713b4e73e743ed842ff0dabb81d256",
      "fd597e59fce045afabbc9c31657499cf",
      "28ec78e36e0142ac8c34311900ba6508",
      "093d1cb1a68945f880a06655f8cfabd7",
      "8bf0fe24a4f54ba5a0b8652e10ccaf70",
      "41e4cfea7c1449288b804a0bdd854d4e",
      "2c53aee091c1464880a589bcc77c1dd7",
      "2bfc5a2ae5494d90b40f57d0e8ece8d0",
      "6af1896107624758abd194fb858b7301",
      "826495552e8a42d99fda69e848da6e19",
      "d17458116ae44d3b91fb86407472b49a",
      "ce47358feb5444849fa4ab5c60d5a890",
      "46288f104de34c8d9582e6834e16cf54",
      "3289d26b3b984ce28d313b225cb2d993",
      "d76fefd292f945c2b8303910e2ba9d33",
      "7378923129de427b9087b175e510e24f",
      "126af16088404d90a2f3e08d163b5e09",
      "1def3965cba9465ca2852ae44234bbc7",
      "ca6b0b6247394ef8b3dc04151e0dcf33",
      "2f4b266af3454ac49c9f6a93d9d77fc2",
      "24df422dd6f944a4a09b192724a1aa80",
      "7fa5735db7c544f5bd5d45a2844a87fd",
      "46bf1b561d7b4b0aa59be66effe7dd50",
      "03488b0fecaa4219ba16270f00a494b0",
      "de798c80ca4c4b97bda7bc9927a914df",
      "547c7f78e48a444fb06db89fdd5159df",
      "3f1a903bc4214521987d061349976e5a",
      "9891192a604a4aae9116cb542e9dc0e6",
      "da1717dff2524c19847797b1d805eecf",
      "084db2ec7b874fa7a355bc4986f7b40e",
      "a7b024cf9d834255b203ce6e4f578bc9",
      "ad0b66c7eefb49b096786ee138ee9afd"
     ]
    },
    "id": "tPJgRLlJ39A-",
    "outputId": "48e13c83-4518-4312-b1c2-17ab67a456a0"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, DataCollatorForLanguageModeling\n",
    "from trl import SFTTrainer\n",
    "\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tok(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=1024)\n",
    "\n",
    "dataset_tok = dataset_fmt.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./qlora-logs\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "\n",
    "collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tok,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_tok[\"train\"],\n",
    "    eval_dataset=dataset_tok[\"validation\"],\n",
    "    args=args,\n",
    "    data_collator=collator,\n",
    "     # IMPORTANT: we already tokenized; packing expects raw text\n",
    ")\n",
    "\n",
    "\n",
    "# 5) Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djb21jsdRiyG",
    "outputId": "6a8a6e16-217c-48f1-e22e-ffb82c79920c"
   },
   "outputs": [],
   "source": [
    "# Save only the LoRA adapters (small) and tokenizer\n",
    "save_dir = \"/content/qlora-log-explainer\"\n",
    "model.save_pretrained(save_dir)\n",
    "tok.save_pretrained(save_dir)\n",
    "\n",
    "print(\"Saved to:\", save_dir)\n",
    "!ls -lh $save_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGOJiBeGqJWb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def test_model(log_line: str):\n",
    "    model.eval()   # put model in evaluation mode\n",
    "\n",
    "    # Create the same style of prompt used during training\n",
    "    prompt = (\n",
    "    \"### Instruction:\\n\"\n",
    "    \"You are an assistant. Respond STRICTLY in this format:\\n\"\n",
    "    \"Cause:\\n<2-3 lines only>\\n\"\n",
    "    \"Fix:\\n<1 line only>\\n\"\n",
    "    \"Do not add extra explanations, repeats, or multiple Cause/Fix blocks.\\n\\n\"\n",
    "    \"### Input:\\n\"\n",
    "    f\"{log_line}\\n\\n\"\n",
    "    \"### Response:\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "    # Convert text → tokens → tensors\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Generate output\n",
    "    with torch.inference_mode():\n",
    "        out = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=150,\n",
    "    do_sample=False,\n",
    "    temperature=0.2,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.15,\n",
    "    no_repeat_ngram_size=4,\n",
    "    pad_token_id=tok.eos_token_id,\n",
    "    eos_token_id=tok.eos_token_id,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    # Decode tokens → text\n",
    "    text = tok.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    # Just return the model’s answer (after \"### Response:\")\n",
    "    return text.split(\"### Response:\")[-1].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSkbwOTWqK-U",
    "outputId": "1271e0be-bcee-4ae6-ccd1-685c04166284"
   },
   "outputs": [],
   "source": [
    "sample_log = \"kafka.common.MessageSizeTooLargeException: Message exceeds the maximum size allowed\"\n",
    "print(test_model(sample_log))\n"
   ]
  }
 ],
 "metadata": {
  "_render_bump": 1,
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
